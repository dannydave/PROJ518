{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd67640",
   "metadata": {},
   "source": [
    "# PROJECT DISSERTATION CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a1429",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39df231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, ttk\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10349247",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('heart_statlog_cleveland_hungary_final.csv')\n",
    "print('The shape of the data is ', dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e15d8",
   "metadata": {},
   "source": [
    "### A preview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(20).style.set_properties(**{'background-color': '#d8e0d5','color': 'black','border-color': 'darkblack'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed6c1e",
   "metadata": {},
   "source": [
    "### Dividing the features into Numerical and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c12cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(dataset.columns)\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "for i in col:\n",
    "    if len(dataset[i].unique()) > 6:\n",
    "        numerical_features.append(i)\n",
    "    else:\n",
    "        categorical_features.append(i)\n",
    "\n",
    "print('Categorical Features :',*categorical_features)\n",
    "print('Numerical Features :',*numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8aa81",
   "metadata": {},
   "source": [
    "### Mapping the categorical features to their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dataset.copy()\n",
    "df1['sex'] = df1['sex'].replace({1: 'male', 0: 'female'})\n",
    "df1['chest pain type'] = df1['chest pain type'].replace({1: 'typical ang', 2: 'atypical ang', 3: 'non-ang', 4: 'asymptomatic'})\n",
    "df1['fasting blood sugar'] = df1['fasting blood sugar'].replace({1: 'true', 0: 'false'})\n",
    "df1['resting ecg'] = df1['resting ecg'].replace({0: 'normal', 1: 'ST-T abnormality', 2: 'LVH'})\n",
    "df1['exercise angina'] = df1['exercise angina'].replace({1: 'yes', 0: 'no'})\n",
    "df1['ST slope'] = df1['ST slope'].replace({1: 'upsloping', 2: 'flat', 3: 'downsloping'})\n",
    "df1['target'] = df1['target'].replace({1: 'heart disease', 0: 'no heart disease'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e956f7",
   "metadata": {},
   "source": [
    "### Visualization of the target feature in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08583700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = list(df1['target'].value_counts())\n",
    "circle = [d[1] / sum(d) * 100, d[0] / sum(d) * 100]\n",
    "colors = ['#2ecc71', '#f7342a']\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(circle, labels=['Normal', 'Heart Disease'], autopct='%1.1f%%', startangle=90, explode=(0.1, 0), colors=colors,\n",
    "        wedgeprops={'edgecolor': 'black', 'linewidth': 1, 'antialiased': True}, textprops={'fontsize': 14})\n",
    "plt.title('Heart Disease (%)', fontsize=18)\n",
    "\n",
    "# Count plot for heart disease cases\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = sns.countplot(x='target', data=df1, palette=colors, edgecolor='black')\n",
    "for rect in ax.patches:\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, rect.get_height() + 2, rect.get_height(), horizontalalignment='center', fontsize=14)\n",
    "ax.set_xticklabels(['Normal', 'Heart Disease'], fontsize=14)\n",
    "ax.set_xlabel('Target', fontsize=16)\n",
    "ax.set_ylabel('Count', fontsize=16)\n",
    "plt.title('Cases of Heart Disease', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d720835",
   "metadata": {},
   "source": [
    "### Visualization of the categorical features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10, 15))\n",
    "for i in range(len(categorical_features) - 1):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    ax = sns.countplot(x=categorical_features[i], data=df1, hue=\"target\", palette=colors, edgecolor='black')\n",
    "    for rect in ax.patches:\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, rect.get_height() + 2, rect.get_height(), horizontalalignment='center', fontsize=11)\n",
    "    title = categorical_features[i] + ' vs Heart Disease'\n",
    "    plt.legend(['Normal', 'Heart Disease'])\n",
    "    plt.title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e62dc9",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing function\n",
    "def data_preprocessing(dataset):\n",
    "    # Handle missing values\n",
    "    missing_values = dataset.isnull().sum()\n",
    "    \n",
    "    # Replace the outlier with the mode of the column\n",
    "    mode_st_slope = dataset['ST slope'].mode()[0]\n",
    "    dataset['ST slope'] = dataset['ST slope'].replace(0, mode_st_slope)\n",
    "    print(\"Outlier replaced with mode:\", mode_st_slope)\n",
    "    \n",
    "    # Split the data into features and target\n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    \n",
    "    # Scale the features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, missing_values\n",
    "\n",
    "# Perform data preprocessing\n",
    "X_train, X_test, y_train, y_test, missing_values = data_preprocessing(dataset)\n",
    "\n",
    "# Print dataset information and missing values\n",
    "print(\"The dataset information:\")\n",
    "print(dataset.info())\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e83be",
   "metadata": {},
   "source": [
    "### Feature Selection, Training and Evaluation of the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c83cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models to evaluate\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=20, criterion='entropy', random_state=0),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Support Vector Machine': SVC(kernel='linear', random_state=0, probability=True)\n",
    "}\n",
    "\n",
    "# Dictionary to store feature importances for each model\n",
    "feature_importance_info = {model_name: None for model_name in models.keys()}\n",
    "\n",
    "# Evaluate models and get feature importances\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):  # For models like SVM with coefficients\n",
    "        importances = np.abs(model.coef_).mean(axis=0)\n",
    "    else:\n",
    "        importances = None\n",
    "    \n",
    "    feature_importance_info[model_name] = importances\n",
    "\n",
    "# Aggregate feature importances across models\n",
    "feature_names = dataset.columns[:-1]\n",
    "aggregate_importances = np.zeros(len(feature_names))\n",
    "for model_name, importances in feature_importance_info.items():\n",
    "    if importances is not None:\n",
    "        aggregate_importances += importances\n",
    "\n",
    "# Normalize aggregated importances\n",
    "aggregate_importances /= len(models)\n",
    "\n",
    "# Sort indices based on aggregated importances\n",
    "indices = np.argsort(aggregate_importances)[::-1]\n",
    "\n",
    "# Create DataFrame to display aggregated feature importances\n",
    "aggregate_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': aggregate_importances})\n",
    "aggregate_importance_df = aggregate_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display aggregated feature importances\n",
    "print(\"\\nAggregate Feature Importances Across Models:\")\n",
    "print(aggregate_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c813cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model performance with selected features\n",
    "def evaluate_model_with_selected_features(model, X_train, X_test, y_train, y_test, indices, num_features):\n",
    "    top_features = indices[:num_features]\n",
    "    X_train_selected = X_train[:, top_features]\n",
    "    X_test_selected = X_test[:, top_features]\n",
    "    \n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate models with increasing number of features\n",
    "results = {model_name: [] for model_name in models.keys()}\n",
    "for num_features in range(1, len(indices) + 1):\n",
    "    for model_name, model in models.items():\n",
    "        accuracy = evaluate_model_with_selected_features(model, X_train, X_test, y_train, y_test, indices, num_features)\n",
    "        results[model_name].append(accuracy)\n",
    "\n",
    "# Plotting the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=aggregate_importance_df, palette='viridis')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Plotting model performance with increasing number of features\n",
    "plt.figure(figsize=(12, 8))\n",
    "for model_name, accuracies in results.items():\n",
    "    plt.plot(range(1, len(indices) + 1), accuracies, label=model_name, marker='o')\n",
    "plt.title('Model Performance with Increasing Number of Features')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e579d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store highest accuracy and corresponding number of features for each model\n",
    "best_accuracy_info = {model_name: {'accuracy': 0, 'num_features': 0} for model_name in models.keys()}\n",
    "\n",
    "# Evaluate models with increasing number of features\n",
    "for num_features in range(1, len(indices) + 1):\n",
    "    for model_name, model in models.items():\n",
    "        accuracy = evaluate_model_with_selected_features(model, X_train, X_test, y_train, y_test, indices, num_features)\n",
    "        if accuracy > best_accuracy_info[model_name]['accuracy']:\n",
    "            best_accuracy_info[model_name]['accuracy'] = accuracy\n",
    "            best_accuracy_info[model_name]['num_features'] = num_features\n",
    "\n",
    "# Print the results\n",
    "for model_name, info in best_accuracy_info.items():\n",
    "    print(f'Model: {model_name}, Highest Accuracy: {info[\"accuracy\"]}, Number of Features: {info[\"num_features\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b99e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select top 11 features \n",
    "top_n = 11\n",
    "top_features = indices[:top_n]\n",
    "X_train_selected = X_train[:, top_features]\n",
    "X_test_selected = X_test[:, top_features]\n",
    "\n",
    "# Store model results\n",
    "model_names = []\n",
    "accuracies = []\n",
    "conf_matrices = []\n",
    "class_reports = []\n",
    "precision_recall_curves = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Train and evaluate each model with selected features\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    print(f'{name} Model with Top {top_n} Features:')\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print('Accuracy:', accuracy)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    class_reports.append(class_report)\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    print('Confusion Matrix:\\n', conf_matrix)\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    precision_recall_curves.append((precision, recall))\n",
    "    \n",
    "    # ROC AUC Score\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_scores = model.predict_proba(X_test_selected)[:, 1]\n",
    "    else:\n",
    "        y_scores = model.decision_function(X_test_selected)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_scores)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    print('ROC_AUC Score:\\n', roc_auc_score(y_test, y_scores))\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_selected, y_train, cv=5, scoring='accuracy')\n",
    "    print(f'{name} Cross-Validation Scores:', cv_scores)\n",
    "    print(f'{name} Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "    print('\\n' + '-'*30 + '\\n')\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
    "    \n",
    "    model_names.append(name)  # Append the model name to the list\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7401f2",
   "metadata": {},
   "source": [
    "### Number of Data point (support) for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9846af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    if hasattr(model, 'support_'):\n",
    "        num_support_vectors_per_class = model.n_support_\n",
    "        print(f'Number of support vectors for each class: {num_support_vectors_per_class}')\n",
    "    else:\n",
    "        print(f'{name} does not use support vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb28b49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply PCA to reduce to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Plot decision boundary function\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    legend1 = plt.legend(*scatter.legend_elements(), title=\"Targets\")\n",
    "    plt.gca().add_artist(legend1)\n",
    "    plt.show()\n",
    "\n",
    "# Train and plot decision boundaries for each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    plot_decision_boundary(model, X_train_pca, y_train, f'{name} Decision Boundary (Train)')\n",
    "    plot_decision_boundary(model, X_test_pca, y_test, f'{name} Decision Boundary (Test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e3690",
   "metadata": {},
   "source": [
    "### Precision - Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b85792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Precision-Recall curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, (precision, recall) in enumerate(precision_recall_curves):\n",
    "    plt.plot(recall, precision, label=model_names[i])\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2fb79",
   "metadata": {},
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Seaborn color palette for better color harmony\n",
    "colors = sns.color_palette(\"colorblind\", len(model_names))\n",
    "\n",
    "# Increase figure size\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot the accuracy comparison\n",
    "bars = plt.bar(model_names, accuracies, width=0.6, color=colors)\n",
    "\n",
    "# Add values on top of the bars for better readability\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f'{yval:.2f}', \n",
    "             ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Add labels, title, and customize appearance\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.title('Accuracy Comparison of the Models', fontsize=18, fontweight='bold', color='#4f4f4f')\n",
    "\n",
    "# Set y-axis limit and add gridlines\n",
    "plt.ylim([0, 1.1])\n",
    "plt.gca().yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Remove top and right spines for a cleaner look\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd2e8c",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for each model\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.ravel()\n",
    "colors = ['#7971e3', '#eb8e46']\n",
    "font_size = 14\n",
    "\n",
    "for i, (name, conf_matrix) in enumerate(zip(model_names, conf_matrices)):\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', ax=axes[i], cmap= colors, cbar=False, annot_kws={\"size\": font_size})\n",
    "    axes[i].set_title(f'{name} Confusion Matrix', fontsize=font_size)\n",
    "    axes[i].set_xlabel('Predicted', fontsize=font_size)\n",
    "    axes[i].set_ylabel('Actual', fontsize=font_size)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce24957",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa923677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract precision for each class from the class reports\n",
    "precision_class_0 = [\n",
    "    report['0']['precision'] for report in class_reports\n",
    "]\n",
    "precision_class_1 = [\n",
    "    report['1']['precision'] for report in class_reports\n",
    "]\n",
    "\n",
    "# Plotting function for precision by class\n",
    "def plot_precision_by_class(model_names, precision_class_0, precision_class_1):\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(model_names))\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    bars1 = plt.bar(index, precision_class_0, bar_width, label='Class 0')\n",
    "    bars2 = plt.bar(index + bar_width, precision_class_1, bar_width, label='Class 1')\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Precision', fontsize=14, fontweight='bold')\n",
    "    plt.title('Precision by Class for Each Model', fontsize=18, fontweight='bold', color='#4f4f4f')\n",
    "    plt.xticks(index + bar_width / 2, model_names)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.legend()\n",
    "    \n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f'{yval:.2f}', \n",
    "                     ha='center', va='bottom', fontsize=12, color='black')\n",
    "    \n",
    "    plt.gca().yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model names for labeling\n",
    "model_names = [\"Decision Tree\", \"Random Forest\", \"Naive Bayes\", \"Support Vector Machine\"]\n",
    "\n",
    "# Plot precision by class\n",
    "plot_precision_by_class(model_names, precision_class_0, precision_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d895ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract recall for each class from the class reports\n",
    "recall_class_0 = [\n",
    "    report['0']['recall'] for report in class_reports\n",
    "]\n",
    "recall_class_1 = [\n",
    "    report['1']['recall'] for report in class_reports\n",
    "]\n",
    "\n",
    "# Plotting function for recall by class\n",
    "def plot_recall_by_class(model_names, recall_class_0, recall_class_1):\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(model_names))\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    bars1 = plt.bar(index, recall_class_0, bar_width, label='Class 0')\n",
    "    bars2 = plt.bar(index + bar_width, recall_class_1, bar_width, label='Class 1')\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Recall', fontsize=14, fontweight='bold')\n",
    "    plt.title('Recall by Class for Each Model', fontsize=18, fontweight='bold', color='#4f4f4f')\n",
    "    plt.xticks(index + bar_width / 2, model_names)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.legend()\n",
    "    \n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f'{yval:.2f}', \n",
    "                     ha='center', va='bottom', fontsize=12, color='black')\n",
    "    \n",
    "    plt.gca().yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model names for labeling\n",
    "model_names = [\"Decision Tree\", \"Random Forest\", \"Naive Bayes\", \"Support Vector Machine\"]\n",
    "\n",
    "# Plot recall by class\n",
    "plot_recall_by_class(model_names, recall_class_0, recall_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae963852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract F1 scores for each class from the class reports\n",
    "f1_class_0 = [\n",
    "    report['0']['f1-score'] for report in class_reports\n",
    "]\n",
    "f1_class_1 = [\n",
    "    report['1']['f1-score'] for report in class_reports\n",
    "]\n",
    "\n",
    "# Plotting function for F1 score by class\n",
    "def plot_f1_by_class(model_names, f1_class_0, f1_class_1):\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(model_names))\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    bars1 = plt.bar(index, f1_class_0, bar_width, label='Class 0')\n",
    "    bars2 = plt.bar(index + bar_width, f1_class_1, bar_width, label='Class 1')\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('F1 Score', fontsize=14, fontweight='bold')\n",
    "    plt.title('F1 Score by Class for Each Model', fontsize=18, fontweight='bold', color='#4f4f4f')\n",
    "    plt.xticks(index + bar_width / 2, model_names)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.legend()\n",
    "    \n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f'{yval:.2f}', \n",
    "                     ha='center', va='bottom', fontsize=12, color='black')\n",
    "    \n",
    "    plt.gca().yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model names for labeling\n",
    "model_names = [\"Decision Tree\", \"Random Forest\", \"Naive Bayes\", \"Support Vector Machine\"]\n",
    "\n",
    "# Plot F1 score by class\n",
    "plot_f1_by_class(model_names, f1_class_0, f1_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b4f3a",
   "metadata": {},
   "source": [
    "### Graphical User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=20, criterion='entropy', random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "with open('random_forest_model.pkl', 'wb') as model_file:\n",
    "    joblib.dump(rf_model, model_file)\n",
    "    \n",
    "# Load the trained Random Forest model\n",
    "with open('random_forest_model.pkl', 'rb') as model_file:\n",
    "    random_model = joblib.load(model_file)\n",
    "\n",
    "def predict_heart_disease():\n",
    "    # Get input values from the user\n",
    "    try:\n",
    "        age = int(entry_age.get())\n",
    "        sex = int(entry_sex.get())\n",
    "        cp = int(entry_cp.get())\n",
    "        trestbps = int(entry_trestbps.get())\n",
    "        chol = int(entry_chol.get())\n",
    "        fbs = int(entry_fbs.get())\n",
    "        restecg = int(entry_restecg.get())\n",
    "        thalach = int(entry_thalach.get())\n",
    "        exang = int(entry_exang.get())\n",
    "        oldpeak = float(entry_oldpeak.get())\n",
    "        slope = int(entry_slope.get())\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Input Error\", \"Please enter valid numeric values for all fields.\")\n",
    "        return\n",
    "\n",
    "    # Create the feature array\n",
    "    features = np.array([[age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope]])\n",
    "    \n",
    "    # Predict using the loaded model\n",
    "    prediction = random_model.predict(features)\n",
    "    \n",
    "    # Display the result\n",
    "    if prediction[0] == 1:\n",
    "        result_text.set(\"The patient is likely to have heart disease.\")\n",
    "    else:\n",
    "        result_text.set(\"The patient is normal.\")\n",
    "    messagebox.showinfo(\"Success\", result_text.get())\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Heart Disease Prediction\")\n",
    "window.geometry(\"500x600\")\n",
    "window.configure(bg='#d3d3d3')\n",
    "\n",
    "# Title\n",
    "title_label = tk.Label(window, text=\"Heart Disease Prediction System\", font=(\"Helvetica\", 20), bg='#d3d3d3', pady=20)\n",
    "title_label.pack()\n",
    "\n",
    "# Frame for the input fields\n",
    "frame = tk.Frame(window, bg='#d3d3d3')\n",
    "frame.pack(pady=10)\n",
    "\n",
    "fields = [\n",
    "    (\"Age\", \"entry_age\"),\n",
    "    (\"Sex (1=Male, 0=Female)\", \"entry_sex\"),\n",
    "    (\"Chest Pain Type (1-4)\", \"entry_cp\"),\n",
    "    (\"Resting Blood Pressure\", \"entry_trestbps\"),\n",
    "    (\"Cholesterol\", \"entry_chol\"),\n",
    "    (\"Fasting Blood Sugar (1 if >120mg/dl, 0 otherwise)\", \"entry_fbs\"),\n",
    "    (\"Resting ECG (0-2)\", \"entry_restecg\"),\n",
    "    (\"Max Heart Rate\", \"entry_thalach\"),\n",
    "    (\"Exercise Induced Angina (1=Yes, 0=No)\", \"entry_exang\"),\n",
    "    (\"Oldpeak\", \"entry_oldpeak\"),\n",
    "    (\"ST Slope (1-3)\", \"entry_slope\")\n",
    "]\n",
    "\n",
    "entries = {}\n",
    "\n",
    "for i, (label_text, var_name) in enumerate(fields):\n",
    "    tk.Label(frame, text=label_text, bg='#d3d3d3').grid(row=i, column=0, padx=10, pady=5, sticky=\"e\")\n",
    "    entries[var_name] = tk.Entry(frame)\n",
    "    entries[var_name].grid(row=i, column=1, padx=10, pady=5, sticky=\"w\")\n",
    "globals().update(entries)\n",
    "\n",
    "# Button to predict\n",
    "predict_button = tk.Button(frame, text=\"Predict\", command=predict_heart_disease, bg='#ff69b4', fg='white', font=(\"Helvetica\", 12))\n",
    "predict_button.grid(row=len(fields), column=0, columnspan=2, pady=20)\n",
    "\n",
    "# Label to display the result\n",
    "result_text = tk.StringVar()\n",
    "result_label = tk.Label(window, textvariable=result_text, fg=\"blue\", font=(\"Helvetica\", 12), bg='#d3d3d3')\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Start the GUI loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fca1ec",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a6ebe",
   "metadata": {},
   "source": [
    "Harris, C.R., Millman, K.J., van der Walt, S.J., et al. (2020). Array programming with NumPy. Nature, 585(7825), 357-362.\n",
    "\n",
    "Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science & Engineering, 9(3), 90-95.\n",
    "\n",
    "Manu Siddhartha (2020). Heart Disease Dataset (Comprehensive). [online] IEEE DataPort. Available at: https://ieee-dataport.org/open-access/heart-disease-dataset-comprehensive [Accessed 1 Jan. 2024].\n",
    "\n",
    "Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825-2830.\n",
    "\n",
    "Python Software Foundation.(n.d.). Tkinter - Python interface to Tcl/Tk [Software]. Available at: https://docs.python.org/3/library/tkinter.html [Accessed 1 June. 2024}\n",
    "\n",
    "Python Software Foundation. (n.d.). joblib - Lightweight pipelining in Python [Software]. Available at: https://joblib.readthedocs.io/ [Accessed 5 June. 2024].\n",
    "\n",
    "Waskom, M. L. (2021). seaborn: statistical data visualization. Journal of Open Source Software, 6(60), 3021."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
